#!/usr/bin/env python3
"""
å¯è¯»æ€§æŒ‡æ ‡æ£€æµ‹å·¥å…·

åˆ†ææ–‡æœ¬çš„å¯è¯»æ€§æŒ‡æ ‡ï¼ŒåŒ…æ‹¬:
- Flesch Reading Ease
- Flesch-Kincaid Grade Level
- Gunning Fog Index
- SMOG Index
- Coleman-Liau Index
- Automated Readability Index (ARI)

ç‰ˆæœ¬: 1.0
åˆ›å»ºæ—¶é—´: 2026-01-10
"""

import re
import argparse
from dataclasses import dataclass, field
from typing import Optional
from pathlib import Path


@dataclass
class ReadabilityReport:
    """å¯è¯»æ€§åˆ†ææŠ¥å‘Š"""
    # åŸºç¡€ç»Ÿè®¡
    total_words: int = 0
    total_sentences: int = 0
    total_syllables: int = 0
    total_characters: int = 0
    complex_words: int = 0  # 3+éŸ³èŠ‚è¯

    # å¯è¯»æ€§æŒ‡æ ‡
    flesch_reading_ease: float = 0.0
    flesch_kincaid_grade: float = 0.0
    gunning_fog: float = 0.0
    smog_index: float = 0.0
    coleman_liau: float = 0.0
    automated_readability_index: float = 0.0

    # ç»¼åˆè¯„åˆ†
    average_grade_level: float = 0.0
    difficulty_level: str = ""  # Easy, Moderate, Difficult, Very Difficult

    # æ”¹è¿›å»ºè®®
    suggestions: list = field(default_factory=list)


class ReadabilityChecker:
    """å¯è¯»æ€§æ£€æµ‹å™¨"""

    # éš¾åº¦çº§åˆ«é˜ˆå€¼
    DIFFICULTY_THRESHOLDS = {
        'Easy': (0, 6),           # å°å­¦æ°´å¹³
        'Moderate': (6, 10),      # åˆä¸­æ°´å¹³
        'Difficult': (10, 14),    # é«˜ä¸­æ°´å¹³
        'Very Difficult': (14, 20),  # å¤§å­¦æ°´å¹³
        'Academic': (20, 100)     # ç ”ç©¶ç”Ÿæ°´å¹³
    }

    # ç›®æ ‡å—ä¼—æ¨è
    AUDIENCE_RECOMMENDATIONS = {
        'general': (6, 8),        # æ™®é€šå¤§ä¼—
        'tech_blog': (8, 12),     # æŠ€æœ¯åšå®¢
        'academic': (12, 16),     # å­¦æœ¯æ–‡ç« 
        'security_report': (10, 14)  # å®‰å…¨æŠ¥å‘Š
    }

    def __init__(self, target_grade: float = 10.0):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨

        Args:
            target_grade: ç›®æ ‡é˜…è¯»ç­‰çº§ï¼ˆé»˜è®¤10ï¼Œé«˜ä¸­æ°´å¹³ï¼‰
        """
        self.target_grade = target_grade

    def _count_syllables(self, word: str) -> int:
        """
        ä¼°ç®—å•è¯éŸ³èŠ‚æ•°ï¼ˆè‹±æ–‡ï¼‰

        åŸºäºè§„åˆ™çš„ç®€åŒ–ç®—æ³•
        """
        word = word.lower().strip()
        if not word:
            return 0

        # å¸¸è§ä¾‹å¤–
        exceptions = {
            'the': 1, 'a': 1, 'an': 1, 'and': 1, 'or': 1,
            'is': 1, 'are': 1, 'was': 1, 'were': 1,
            'have': 1, 'has': 1, 'had': 1,
            'security': 4, 'vulnerability': 6, 'authentication': 5,
            'authorization': 5, 'infrastructure': 4, 'implementation': 5
        }
        if word in exceptions:
            return exceptions[word]

        # åŸºæœ¬è§„åˆ™
        vowels = 'aeiouy'
        count = 0
        prev_vowel = False

        for i, char in enumerate(word):
            is_vowel = char in vowels
            if is_vowel and not prev_vowel:
                count += 1
            prev_vowel = is_vowel

        # è°ƒæ•´è§„åˆ™
        # ç»“å°¾çš„eé€šå¸¸ä¸å‘éŸ³
        if word.endswith('e') and count > 1:
            count -= 1
        # ç»“å°¾çš„leé€šå¸¸æ˜¯ä¸€ä¸ªéŸ³èŠ‚
        if word.endswith('le') and len(word) > 2 and word[-3] not in vowels:
            count += 1
        # ç»“å°¾çš„edé€šå¸¸ä¸å¢åŠ éŸ³èŠ‚ï¼ˆé™¤éå‰é¢æ˜¯tæˆ–dï¼‰
        if word.endswith('ed') and len(word) > 2 and word[-3] not in 'td':
            count = max(1, count)

        return max(1, count)

    def _count_chinese_characters(self, text: str) -> int:
        """ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•°"""
        return len(re.findall(r'[\u4e00-\u9fff]', text))

    def _is_complex_word(self, word: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¤æ‚è¯ï¼ˆ3+éŸ³èŠ‚ï¼‰"""
        return self._count_syllables(word) >= 3

    def _tokenize_sentences(self, text: str) -> list:
        """åˆ†å¥"""
        # å¤„ç†å¸¸è§å¥æœ«æ ‡ç‚¹
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]+', text)
        # è¿‡æ»¤ç©ºå¥å­
        return [s.strip() for s in sentences if s.strip()]

    def _tokenize_words(self, text: str) -> list:
        """åˆ†è¯ï¼ˆä»…è‹±æ–‡ï¼‰"""
        # ç§»é™¤ä¸­æ–‡å­—ç¬¦ååˆ†è¯
        text_en = re.sub(r'[\u4e00-\u9fff]', ' ', text)
        words = re.findall(r'[a-zA-Z]+', text_en)
        return [w.lower() for w in words if len(w) > 0]

    def analyze(self, text: str) -> ReadabilityReport:
        """
        åˆ†ææ–‡æœ¬å¯è¯»æ€§

        Args:
            text: è¦åˆ†æçš„æ–‡æœ¬

        Returns:
            ReadabilityReport: å¯è¯»æ€§æŠ¥å‘Š
        """
        report = ReadabilityReport()

        # æ¸…ç†Markdownæ ¼å¼
        clean_text = self._clean_markdown(text)

        # åŸºç¡€ç»Ÿè®¡
        sentences = self._tokenize_sentences(clean_text)
        words = self._tokenize_words(clean_text)
        chinese_chars = self._count_chinese_characters(clean_text)

        report.total_sentences = len(sentences)
        report.total_words = len(words) + chinese_chars  # ä¸­æ–‡å­—ç¬¦è®¡å…¥
        report.total_characters = len(re.sub(r'\s', '', clean_text))

        # å¦‚æœè¯æ•°å¤ªå°‘ï¼Œè¿”å›é»˜è®¤æŠ¥å‘Š
        if len(words) < 10:
            report.suggestions.append("æ–‡æœ¬è¿‡çŸ­ï¼Œæ— æ³•è¿›è¡Œå‡†ç¡®çš„å¯è¯»æ€§åˆ†æ")
            report.difficulty_level = "Unknown"
            return report

        # è®¡ç®—è‹±æ–‡ç»Ÿè®¡ï¼ˆç”¨äºå¯è¯»æ€§å…¬å¼ï¼‰
        report.total_syllables = sum(self._count_syllables(w) for w in words)
        report.complex_words = sum(1 for w in words if self._is_complex_word(w))

        # è®¡ç®—å„é¡¹æŒ‡æ ‡ï¼ˆä½¿ç”¨è‹±æ–‡è¯æ±‡ç»Ÿè®¡ï¼‰
        word_count = len(words)
        sentence_count = max(1, report.total_sentences)
        syllable_count = report.total_syllables
        char_count = sum(len(w) for w in words)
        complex_count = report.complex_words

        # Flesch Reading Ease: 206.835 - 1.015*(words/sentences) - 84.6*(syllables/words)
        # åˆ†æ•°è¶Šé«˜è¶Šæ˜“è¯»ï¼ˆ0-100ï¼‰
        words_per_sentence = word_count / sentence_count
        syllables_per_word = syllable_count / max(1, word_count)
        report.flesch_reading_ease = max(0, min(100,
            206.835 - 1.015 * words_per_sentence - 84.6 * syllables_per_word
        ))

        # Flesch-Kincaid Grade Level
        report.flesch_kincaid_grade = (
            0.39 * words_per_sentence +
            11.8 * syllables_per_word -
            15.59
        )

        # Gunning Fog Index
        complex_ratio = complex_count / max(1, word_count)
        report.gunning_fog = 0.4 * (words_per_sentence + 100 * complex_ratio)

        # SMOG Index (éœ€è¦è‡³å°‘30å¥)
        if sentence_count >= 3:
            report.smog_index = 1.0430 * (complex_count * (30 / sentence_count)) ** 0.5 + 3.1291
        else:
            report.smog_index = report.flesch_kincaid_grade  # å›é€€

        # Coleman-Liau Index
        L = (char_count / word_count) * 100  # æ¯100è¯çš„å­—æ¯æ•°
        S = (sentence_count / word_count) * 100  # æ¯100è¯çš„å¥å­æ•°
        report.coleman_liau = 0.0588 * L - 0.296 * S - 15.8

        # Automated Readability Index (ARI)
        report.automated_readability_index = (
            4.71 * (char_count / word_count) +
            0.5 * words_per_sentence -
            21.43
        )

        # è®¡ç®—å¹³å‡ç­‰çº§
        grades = [
            report.flesch_kincaid_grade,
            report.gunning_fog,
            report.smog_index,
            report.coleman_liau,
            report.automated_readability_index
        ]
        report.average_grade_level = sum(grades) / len(grades)

        # ç¡®å®šéš¾åº¦çº§åˆ«
        avg = report.average_grade_level
        for level, (low, high) in self.DIFFICULTY_THRESHOLDS.items():
            if low <= avg < high:
                report.difficulty_level = level
                break
        else:
            report.difficulty_level = "Academic"

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        report.suggestions = self._generate_suggestions(report)

        return report

    def _clean_markdown(self, text: str) -> str:
        """æ¸…ç†Markdownæ ¼å¼"""
        # ç§»é™¤ä»£ç å—
        text = re.sub(r'```[\s\S]*?```', '', text)
        text = re.sub(r'`[^`]+`', '', text)
        # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬
        text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
        # ç§»é™¤å›¾ç‰‡
        text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
        # ç§»é™¤æ ‡é¢˜æ ‡è®°
        text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)
        # ç§»é™¤åˆ—è¡¨æ ‡è®°
        text = re.sub(r'^[\*\-\+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\d+\.\s+', '', text, flags=re.MULTILINE)
        # ç§»é™¤ç²—ä½“/æ–œä½“
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
        text = re.sub(r'\*([^*]+)\*', r'\1', text)
        text = re.sub(r'__([^_]+)__', r'\1', text)
        text = re.sub(r'_([^_]+)_', r'\1', text)
        # ç§»é™¤è¡¨æ ¼åˆ†éš”ç¬¦
        text = re.sub(r'\|[-:]+\|', '', text)
        text = re.sub(r'\|', ' ', text)

        return text

    def _generate_suggestions(self, report: ReadabilityReport) -> list:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        # åŸºäºç›®æ ‡ç­‰çº§çš„å»ºè®®
        diff = report.average_grade_level - self.target_grade

        if diff > 3:
            suggestions.append(f"æ–‡æœ¬é˜…è¯»éš¾åº¦è¿‡é«˜ï¼ˆ{report.average_grade_level:.1f}çº§ï¼‰ï¼Œå»ºè®®é™è‡³{self.target_grade:.0f}çº§ä»¥ä¸‹")
        elif diff > 1:
            suggestions.append(f"æ–‡æœ¬é˜…è¯»éš¾åº¦ç•¥é«˜ï¼ˆ{report.average_grade_level:.1f}çº§ï¼‰ï¼Œå¯è€ƒè™‘ç®€åŒ–")
        elif diff < -3:
            suggestions.append(f"æ–‡æœ¬é˜…è¯»éš¾åº¦è¾ƒä½ï¼ˆ{report.average_grade_level:.1f}çº§ï¼‰ï¼Œå¯é€‚å½“å¢åŠ ä¸“ä¸šæ·±åº¦")

        # åŸºäºæŒ‡æ ‡çš„å…·ä½“å»ºè®®
        if report.total_sentences > 0:
            words_per_sentence = report.total_words / report.total_sentences
            if words_per_sentence > 25:
                suggestions.append(f"å¥å­è¿‡é•¿ï¼ˆå¹³å‡{words_per_sentence:.1f}è¯/å¥ï¼‰ï¼Œå»ºè®®æ‹†åˆ†é•¿å¥ï¼Œç›®æ ‡15-20è¯/å¥")
            elif words_per_sentence < 10:
                suggestions.append(f"å¥å­è¿‡çŸ­ï¼ˆå¹³å‡{words_per_sentence:.1f}è¯/å¥ï¼‰ï¼Œå¯é€‚å½“ç»„åˆç›¸å…³å†…å®¹")

        if report.total_words > 0:
            complex_ratio = report.complex_words / report.total_words
            if complex_ratio > 0.2:
                suggestions.append(f"å¤æ‚è¯æ±‡è¿‡å¤šï¼ˆ{complex_ratio*100:.1f}%ï¼‰ï¼Œå»ºè®®ç”¨ç®€å•è¯æ›¿æ¢éƒ¨åˆ†ä¸“ä¸šæœ¯è¯­")

        if report.flesch_reading_ease < 30:
            suggestions.append("Flesché˜…è¯»éš¾åº¦è¯„åˆ†è¿‡ä½ï¼Œæ–‡æœ¬éå¸¸éš¾è¯»ï¼Œå»ºè®®å¤§å¹…ç®€åŒ–")
        elif report.flesch_reading_ease < 50:
            suggestions.append("Flesché˜…è¯»éš¾åº¦è¯„åˆ†è¾ƒä½ï¼Œé€‚åˆä¸“ä¸šè¯»è€…ï¼Œæ™®é€šè¯»è€…å¯èƒ½éš¾ä»¥ç†è§£")

        # GEOä¼˜åŒ–å»ºè®®
        if report.difficulty_level in ['Very Difficult', 'Academic']:
            suggestions.append("å¯¹äºAIæœç´¢å¼•æ“å¼•ç”¨ï¼Œå»ºè®®åœ¨æ–‡ç« å¼€å¤´æä¾›ç®€åŒ–çš„æ‘˜è¦æˆ–å…³é”®è¦ç‚¹")

        return suggestions

    def get_grade_level_recommendation(self, audience: str = 'general') -> tuple:
        """
        è·å–ç›®æ ‡å—ä¼—çš„æ¨èé˜…è¯»ç­‰çº§

        Args:
            audience: ç›®æ ‡å—ä¼—ç±»å‹

        Returns:
            (min_grade, max_grade): æ¨èç­‰çº§èŒƒå›´
        """
        return self.AUDIENCE_RECOMMENDATIONS.get(audience, (8, 12))

    def format_report(self, report: ReadabilityReport) -> str:
        """æ ¼å¼åŒ–è¾“å‡ºæŠ¥å‘Š"""
        output = "## ğŸ“Š å¯è¯»æ€§åˆ†ææŠ¥å‘Š\n\n"

        # åŸºç¡€ç»Ÿè®¡
        output += "### åŸºç¡€ç»Ÿè®¡\n"
        output += f"- æ€»è¯æ•°: {report.total_words}\n"
        output += f"- æ€»å¥æ•°: {report.total_sentences}\n"
        output += f"- å¤æ‚è¯æ•°: {report.complex_words}"
        if report.total_words > 0:
            output += f" ({report.complex_words/report.total_words*100:.1f}%)"
        output += "\n"
        output += f"- æ€»éŸ³èŠ‚æ•°: {report.total_syllables}\n\n"

        # å¯è¯»æ€§æŒ‡æ ‡
        output += "### å¯è¯»æ€§æŒ‡æ ‡\n"
        output += f"| æŒ‡æ ‡ | åˆ†æ•° | è¯´æ˜ |\n"
        output += f"|------|------|------|\n"
        output += f"| Flesch Reading Ease | {report.flesch_reading_ease:.1f} | 0-100ï¼Œè¶Šé«˜è¶Šæ˜“è¯» |\n"
        output += f"| Flesch-Kincaid Grade | {report.flesch_kincaid_grade:.1f} | ç¾å›½å­¦æ ¡å¹´çº§ |\n"
        output += f"| Gunning Fog | {report.gunning_fog:.1f} | éœ€è¦çš„æ•™è‚²å¹´é™ |\n"
        output += f"| SMOG Index | {report.smog_index:.1f} | ç†è§£æ‰€éœ€å¹´çº§ |\n"
        output += f"| Coleman-Liau | {report.coleman_liau:.1f} | å¹´çº§æ°´å¹³ |\n"
        output += f"| ARI | {report.automated_readability_index:.1f} | å¹´çº§æ°´å¹³ |\n\n"

        # ç»¼åˆè¯„ä¼°
        output += "### ç»¼åˆè¯„ä¼°\n"
        output += f"- **å¹³å‡é˜…è¯»ç­‰çº§**: {report.average_grade_level:.1f}\n"
        output += f"- **éš¾åº¦çº§åˆ«**: {report.difficulty_level}\n\n"

        # éš¾åº¦å¯¹ç…§è¡¨
        output += "### éš¾åº¦å¯¹ç…§\n"
        output += "| çº§åˆ« | å¹´çº§èŒƒå›´ | é€‚åˆå—ä¼— |\n"
        output += "|------|----------|----------|\n"
        output += "| Easy | 0-6 | å°å­¦ç”Ÿã€æ™®é€šå¤§ä¼— |\n"
        output += "| Moderate | 6-10 | åˆä¸­ç”Ÿã€åšå®¢è¯»è€… |\n"
        output += "| Difficult | 10-14 | é«˜ä¸­ç”Ÿã€æŠ€æœ¯äººå‘˜ |\n"
        output += "| Very Difficult | 14-20 | å¤§å­¦ç”Ÿã€ä¸“ä¸šäººå£« |\n"
        output += "| Academic | 20+ | ç ”ç©¶ç”Ÿã€å­¦æœ¯é¢†åŸŸ |\n\n"

        # æ”¹è¿›å»ºè®®
        if report.suggestions:
            output += "### æ”¹è¿›å»ºè®®\n"
            for i, suggestion in enumerate(report.suggestions, 1):
                output += f"{i}. {suggestion}\n"

        return output


def main():
    parser = argparse.ArgumentParser(description='å¯è¯»æ€§åˆ†æå·¥å…·')
    parser.add_argument('file', help='è¦åˆ†æçš„Markdownæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--target', '-t', type=float, default=10.0,
                        help='ç›®æ ‡é˜…è¯»ç­‰çº§ï¼ˆé»˜è®¤10ï¼‰')
    parser.add_argument('--audience', '-a',
                        choices=['general', 'tech_blog', 'academic', 'security_report'],
                        default='tech_blog', help='ç›®æ ‡å—ä¼—')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--json', action='store_true', help='è¾“å‡ºJSONæ ¼å¼')

    args = parser.parse_args()

    # è¯»å–æ–‡ä»¶
    file_path = Path(args.file)
    if not file_path.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {args.file}")
        return 1

    content = file_path.read_text(encoding='utf-8')

    # åˆ†æ
    checker = ReadabilityChecker(target_grade=args.target)
    report = checker.analyze(content)

    # è¾“å‡º
    if args.json:
        import json
        from dataclasses import asdict
        output = json.dumps(asdict(report), ensure_ascii=False, indent=2)
    else:
        output = checker.format_report(report)

        # æ·»åŠ å—ä¼—æ¨è
        min_grade, max_grade = checker.get_grade_level_recommendation(args.audience)
        output += f"\n### å—ä¼—æ¨è\n"
        output += f"- ç›®æ ‡å—ä¼—: {args.audience}\n"
        output += f"- æ¨èç­‰çº§: {min_grade}-{max_grade}\n"

        if report.average_grade_level < min_grade:
            output += f"- åˆ¤å®š: âš ï¸ éš¾åº¦åä½ï¼Œå¯å¢åŠ ä¸“ä¸šæ·±åº¦\n"
        elif report.average_grade_level > max_grade:
            output += f"- åˆ¤å®š: âš ï¸ éš¾åº¦åé«˜ï¼Œå»ºè®®ç®€åŒ–\n"
        else:
            output += f"- åˆ¤å®š: âœ… éš¾åº¦é€‚ä¸­ï¼Œç¬¦åˆç›®æ ‡å—ä¼—\n"

    if args.output:
        Path(args.output).write_text(output, encoding='utf-8')
        print(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
    else:
        print(output)

    return 0


if __name__ == '__main__':
    exit(main())
