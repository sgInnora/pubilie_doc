#!/usr/bin/env python3
"""
Publisher Agent

è´Ÿè´£å¤šå¹³å°å‘å¸ƒã€æ ¼å¼é€‚é…å’ŒSEOä¼˜åŒ–ã€‚
"""

from typing import Optional, List, Any, Dict
from pathlib import Path
from datetime import datetime
import re
from .config import AGENT_ROLES, AgentConfig


def create_publisher_agent(
    config: Optional[AgentConfig] = None,
    tools: Optional[List[Any]] = None,
    **kwargs
):
    """
    åˆ›å»ºPublisher Agent

    Args:
        config: Agenté…ç½®
        tools: å¯ç”¨å·¥å…·åˆ—è¡¨
        **kwargs: é¢å¤–å‚æ•°è¦†ç›–é»˜è®¤é…ç½®

    Returns:
        CrewAI Agentå®ä¾‹
    """
    try:
        from crewai import Agent
    except ImportError:
        from .researcher import MockAgent
        return MockAgent('publisher', AGENT_ROLES['publisher'])

    config = config or AgentConfig()
    role_config = AGENT_ROLES['publisher']

    agent_params = {
        'role': role_config['role'],
        'goal': role_config['goal'],
        'backstory': role_config['backstory'],
        'verbose': config.verbose,
        'allow_delegation': kwargs.get('allow_delegation', False),
        'max_iter': config.max_iter,
        'max_retry_limit': config.max_retry_limit,
    }

    if config.llm_model:
        agent_params['llm'] = config.llm_model

    if tools:
        agent_params['tools'] = tools

    agent_params.update(kwargs)

    return Agent(**agent_params)


# å¹³å°é…ç½®
PLATFORM_CONFIGS = {
    'github': {
        'name': 'GitHub',
        'format': 'markdown',
        'max_length': None,
        'features': ['code_blocks', 'tables', 'images', 'anchors'],
        'naming_convention': '{title}_EN.md / {title}_CN.md',
        'frontmatter': False,
        'canonical_method': 'readme_link',
    },
    'medium': {
        'name': 'Medium',
        'format': 'markdown',
        'max_length': 15000,  # çº¦15åˆ†é’Ÿé˜…è¯»
        'features': ['images', 'embeds', 'quotes', 'code_blocks'],
        'naming_convention': 'N/A (web editor)',
        'frontmatter': False,
        'canonical_method': 'api',
        'api_field': 'canonicalUrl',
    },
    'devto': {
        'name': 'Dev.to',
        'format': 'markdown',
        'max_length': None,
        'features': ['code_blocks', 'liquid_tags', 'embeds'],
        'naming_convention': 'article-title.md',
        'frontmatter': True,
        'frontmatter_fields': ['title', 'published', 'tags', 'canonical_url', 'cover_image'],
        'canonical_method': 'frontmatter',
    },
    'linkedin': {
        'name': 'LinkedIn',
        'format': 'rich_text',
        'max_length': 3000,  # æ–‡ç« æ¨¡å¼
        'features': ['images', 'mentions', 'hashtags'],
        'naming_convention': 'N/A (web editor)',
        'frontmatter': False,
        'canonical_method': 'footer_link',
    },
    'twitter': {
        'name': 'Twitter/X',
        'format': 'threads',
        'max_length': 280,  # å•æ¡
        'thread_max': 25,
        'features': ['images', 'links', 'hashtags', 'mentions'],
        'naming_convention': 'N/A (API/web)',
        'frontmatter': False,
        'canonical_method': 'link_card',
    },
}


class PlatformAdapter:
    """å¹³å°å†…å®¹é€‚é…å™¨"""

    def __init__(self, primary_domain: str = "https://innora.ai/blog"):
        self.primary_domain = primary_domain
        self.platforms = PLATFORM_CONFIGS

    def adapt_for_platform(
        self,
        content: str,
        platform: str,
        metadata: Optional[Dict] = None
    ) -> str:
        """
        ä¸ºæŒ‡å®šå¹³å°é€‚é…å†…å®¹

        Args:
            content: åŸå§‹Markdownå†…å®¹
            platform: ç›®æ ‡å¹³å°
            metadata: æ–‡ç« å…ƒæ•°æ®

        Returns:
            é€‚é…åçš„å†…å®¹
        """
        if platform not in self.platforms:
            raise ValueError(f"Unknown platform: {platform}. "
                             f"Available: {list(self.platforms.keys())}")

        config = self.platforms[platform]
        metadata = metadata or {}

        # æå–æ ‡é¢˜
        title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        title = title_match.group(1) if title_match else metadata.get('title', 'Untitled')

        # ç”ŸæˆCanonical URL
        canonical_url = self._generate_canonical_url(title, metadata)

        # æ ¹æ®å¹³å°å¤„ç†
        if platform == 'github':
            return self._adapt_github(content, title, canonical_url)
        elif platform == 'medium':
            return self._adapt_medium(content, title, canonical_url)
        elif platform == 'devto':
            return self._adapt_devto(content, title, canonical_url, metadata)
        elif platform == 'linkedin':
            return self._adapt_linkedin(content, title, canonical_url)
        elif platform == 'twitter':
            return self._adapt_twitter(content, title, canonical_url)

        return content

    def _generate_canonical_url(self, title: str, metadata: Dict) -> str:
        """ç”ŸæˆCanonical URL"""
        if 'canonical_url' in metadata:
            return metadata['canonical_url']

        # ä»æ ‡é¢˜ç”Ÿæˆslug
        slug = title.lower()
        slug = re.sub(r'[^\w\s-]', '', slug)
        slug = re.sub(r'[\s_]+', '-', slug)
        slug = slug.strip('-')[:50]

        date = metadata.get('date', datetime.now().strftime('%Y/%m'))
        return f"{self.primary_domain}/{date}/{slug}"

    def _adapt_github(self, content: str, title: str, canonical_url: str) -> str:
        """é€‚é…GitHubæ ¼å¼"""
        # GitHub Markdownä¿æŒåŸæ ·ï¼Œæ·»åŠ é¡¶éƒ¨é“¾æ¥
        header = f"> ğŸ“„ Full article: [{title}]({canonical_url})\n\n"
        return header + content

    def _adapt_medium(self, content: str, title: str, canonical_url: str) -> str:
        """é€‚é…Mediumæ ¼å¼"""
        # Mediuméœ€è¦é€šè¿‡APIè®¾ç½®canonicalUrlï¼Œå†…å®¹ä¿æŒMarkdown
        # æ·»åŠ åº•éƒ¨ä¿¡æ¯
        footer = f"\n\n---\n\n*Originally published at [{self.primary_domain}]({canonical_url})*"
        return content + footer

    def _adapt_devto(
        self,
        content: str,
        title: str,
        canonical_url: str,
        metadata: Dict
    ) -> str:
        """é€‚é…Dev.toæ ¼å¼"""
        # ç”Ÿæˆfrontmatter
        tags = metadata.get('tags', ['security', 'cybersecurity'])
        if isinstance(tags, str):
            tags = [t.strip() for t in tags.split(',')]
        tags = tags[:4]  # Dev.toæœ€å¤š4ä¸ªæ ‡ç­¾

        frontmatter = f"""---
title: "{title}"
published: true
tags: {', '.join(tags)}
canonical_url: {canonical_url}
---

"""
        # ç§»é™¤åŸæœ‰frontmatterå¦‚æœæœ‰
        content = re.sub(r'^---.*?---\s*', '', content, flags=re.DOTALL)

        return frontmatter + content

    def _adapt_linkedin(self, content: str, title: str, canonical_url: str) -> str:
        """é€‚é…LinkedInæ ¼å¼"""
        config = self.platforms['linkedin']
        max_length = config['max_length']

        # ç§»é™¤Markdownæ ¼å¼
        text = self._strip_markdown(content)

        # æˆªæ–­åˆ°é™åˆ¶é•¿åº¦
        if len(text) > max_length:
            text = text[:max_length - 100] + "...\n\n"
            text += f"ğŸ“– Read the full article: {canonical_url}"
        else:
            text += f"\n\n---\n\n*Originally published at: {canonical_url}*"

        # æ·»åŠ hashtags
        text += "\n\n#Cybersecurity #InfoSec #ThreatIntelligence"

        return text

    def _adapt_twitter(self, content: str, title: str, canonical_url: str) -> str:
        """é€‚é…Twitterçº¿ç¨‹æ ¼å¼"""
        # æå–å…³é”®ç‚¹ç”Ÿæˆçº¿ç¨‹
        sections = re.split(r'\n##\s+', content)
        threads = []

        # é¦–æ¡æ¨æ–‡
        first_tweet = f"ğŸ”’ {title}\n\nA thread ğŸ§µ\n\n{canonical_url}"
        threads.append(first_tweet)

        # ä»å„sectionæå–è¦ç‚¹
        for section in sections[1:6]:  # æœ€å¤š5ä¸ªsection
            lines = section.split('\n')
            section_title = lines[0].strip()
            # æå–ç¬¬ä¸€ä¸ªè¦ç‚¹
            for line in lines[1:]:
                line = line.strip()
                if line and not line.startswith('#'):
                    point = self._strip_markdown(line)[:250]
                    tweet = f"ğŸ“Œ {section_title}\n\n{point}"
                    threads.append(tweet)
                    break

        # ç»“å°¾æ¨æ–‡
        threads.append(f"ğŸ“– Full analysis here: {canonical_url}\n\nLike and retweet if you found this useful! ğŸ™")

        return "\n\n---\n\n".join(threads)

    def _strip_markdown(self, text: str) -> str:
        """ç§»é™¤Markdownæ ¼å¼"""
        # ç§»é™¤æ ‡é¢˜æ ‡è®°
        text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)
        # ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡å­—
        text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
        # ç§»é™¤ç²—ä½“/æ–œä½“
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
        text = re.sub(r'\*([^*]+)\*', r'\1', text)
        # ç§»é™¤ä»£ç å—
        text = re.sub(r'```[\s\S]*?```', '[code block]', text)
        text = re.sub(r'`([^`]+)`', r'\1', text)
        # ç§»é™¤å›¾ç‰‡
        text = re.sub(r'!\[([^\]]*)\]\([^)]+\)', r'[Image: \1]', text)

        return text.strip()


class PublishingChecklist:
    """å‘å¸ƒæ£€æŸ¥æ¸…å•"""

    CHECKLIST = {
        'pre_publish': [
            'AIæ£€æµ‹ç‡ < 15%',
            'å¯è¯»æ€§è¯„åˆ† > 60',
            'æ‹¼å†™å’Œè¯­æ³•æ£€æŸ¥é€šè¿‡',
            'æ‰€æœ‰é“¾æ¥å¯è®¿é—®',
            'å›¾ç‰‡æœ‰altæ–‡æœ¬',
            'Schema Markupå·²æ·»åŠ ',
        ],
        'seo': [
            'æ ‡é¢˜åŒ…å«å…³é”®è¯',
            'æè¿°åœ¨155å­—ç¬¦å†…',
            'æœ‰H2/H3å±‚çº§ç»“æ„',
            'å†…éƒ¨é“¾æ¥å·²æ·»åŠ ',
            'Canonical URLå·²è®¾ç½®',
        ],
        'platform_specific': {
            'github': ['READMEé“¾æ¥æ›´æ–°', 'ç›®å½•ç»“æ„æ­£ç¡®'],
            'medium': ['å°é¢å›¾ç‰‡å·²ä¸Šä¼ ', 'æ ‡ç­¾å·²æ·»åŠ ï¼ˆæœ€å¤š5ä¸ªï¼‰'],
            'devto': ['frontmatterå®Œæ•´', 'æ ‡ç­¾å·²æ·»åŠ ï¼ˆæœ€å¤š4ä¸ªï¼‰'],
            'linkedin': ['æ‘˜è¦ç‰ˆæœ¬å·²å‡†å¤‡', 'hashtagså·²æ·»åŠ '],
            'twitter': ['çº¿ç¨‹å·²åˆ†å‰²', 'å…³é”®ç‚¹å·²æç‚¼'],
        },
    }

    @classmethod
    def get_checklist(cls, platform: Optional[str] = None) -> Dict:
        """è·å–å‘å¸ƒæ£€æŸ¥æ¸…å•"""
        checklist = {
            'pre_publish': cls.CHECKLIST['pre_publish'],
            'seo': cls.CHECKLIST['seo'],
        }

        if platform and platform in cls.CHECKLIST['platform_specific']:
            checklist['platform_specific'] = cls.CHECKLIST['platform_specific'][platform]

        return checklist


# å‘å¸ƒæ—¶é—´å»ºè®®
OPTIMAL_POSTING_TIMES = {
    'github': {
        'best_days': ['Tuesday', 'Wednesday', 'Thursday'],
        'best_hours': ['10:00', '14:00'],
        'timezone': 'UTC',
    },
    'medium': {
        'best_days': ['Tuesday', 'Wednesday'],
        'best_hours': ['08:00', '11:00'],
        'timezone': 'EST',
    },
    'devto': {
        'best_days': ['Monday', 'Tuesday', 'Wednesday'],
        'best_hours': ['07:00', '12:00'],
        'timezone': 'UTC',
    },
    'linkedin': {
        'best_days': ['Tuesday', 'Wednesday', 'Thursday'],
        'best_hours': ['08:00', '10:00', '12:00'],
        'timezone': 'EST',
    },
    'twitter': {
        'best_days': ['Wednesday', 'Thursday'],
        'best_hours': ['09:00', '12:00', '17:00'],
        'timezone': 'EST',
    },
}


def get_optimal_posting_time(platform: str) -> Dict:
    """è·å–å¹³å°æœ€ä½³å‘å¸ƒæ—¶é—´"""
    if platform not in OPTIMAL_POSTING_TIMES:
        return {'message': f'No data for {platform}'}
    return OPTIMAL_POSTING_TIMES[platform]
